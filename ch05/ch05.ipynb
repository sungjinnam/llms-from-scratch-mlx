{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4738cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c0622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0bf8ad",
   "metadata": {},
   "source": [
    "# Evaluating text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ff7693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.09999999999999998)\n",
       "  (trf_blocks): Sequential(\n",
       "    (layers.0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(input_dims=768, output_dims=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256, \n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12, \n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1, \n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "\n",
    "mx.random.seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe17449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = mx.array(encoded)[None, :]\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze().tolist()\n",
    "    return tokenizer.decode(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4a1830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every effort moves you DMVSK DMVieversseparSKseparseparseparsepar'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b7a4c6",
   "metadata": {},
   "source": [
    "## Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32900a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = mx.array([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                   [40, 1107, 588]])      #  \"I really like\"]\n",
    "targets = mx.array([[3626, 6100, 345],    # [\" effort moves you\"\n",
    "                    [1107, 588, 11311]])  #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d29abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1.08953e-05, 1.54743e-05, 5.29234e-05, ..., 1.1125e-05, 1.47884e-05, 1.07763e-05],\n",
       "         [1.16216e-05, 2.01177e-05, 6.33257e-05, ..., 1.26e-05, 8.72894e-06, 1.6723e-05],\n",
       "         [1.16933e-05, 2.81832e-05, 5.13414e-05, ..., 1.21165e-05, 1.2233e-05, 1.76848e-05]],\n",
       "        [[1.78601e-05, 1.22162e-05, 1.27557e-05, ..., 2.22658e-05, 2.96495e-05, 3.25666e-06],\n",
       "         [1.47091e-05, 1.38527e-05, 1.48364e-05, ..., 2.22301e-05, 2.02625e-05, 4.84638e-06],\n",
       "         [1.36925e-05, 1.54772e-05, 1.60843e-05, ..., 2.20074e-05, 1.94253e-05, 6.39406e-06]]], dtype=float32),\n",
       " (2, 3, 50257))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(mx.stop_gradient(inputs))\n",
    "probas = nn.softmax(logits, axis=-1)\n",
    "probas, probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff1a6058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[33548],\n",
       "        [38162],\n",
       "        [38162]],\n",
       "       [[16272],\n",
       "        [16272],\n",
       "        [16272]]], dtype=uint32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = mx.argmax(probas, axis=-1, keepdims=True)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac0c1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: 501YRYR\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e525799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: array([1.9632e-05, 1.4344e-05, 1.21008e-05], dtype=float32)\n",
      "Text 2: array([1.32206e-05, 6.42074e-06, 1.168e-05], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b911e1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.8384, -11.1522, -11.3222, -11.2337, -11.956, -11.3576], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to maximize the log probability of the targets\n",
    "log_probas = mx.log(mx.concat([target_probas_1, target_probas_2], axis=0))\n",
    "log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb698e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-11.31, dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_log_probas = mx.mean(log_probas)\n",
    "avg_log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d92363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(11.31, dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in training, we minimize the negative log likelihood\n",
    "neg_avg_log_probas = -avg_log_probas\n",
    "neg_avg_log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9198c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 50257), (6,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.flatten(0, 1).shape, targets.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d63b4d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(11.31, dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.losses.cross_entropy(logits.flatten(0, 1), targets.flatten(),\n",
    "                               reduction=\"mean\")\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c02a1d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(81635.5, dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perplexity is exp of the cross-entropy loss\n",
    "perplexity = mx.exp(loss)\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390277b6",
   "metadata": {},
   "source": [
    "## Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5a62088",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../ch02/the-verdict.txt\", \"r\") as f:\n",
    "    text_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adedbea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no ',\n",
       " 'it for me! The Strouds stand alone, and happen once--but there\\'s no exterminating our kind of art.\"')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[:99], text_data[-99:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b27811b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20479, 5145)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_characters, total_tokens = len(text_data), len(tokenizer.encode(text_data))\n",
    "total_characters, total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a1aa9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "(2, 256) (2, 256)\n",
      "(2, 256) (2, 256)\n",
      "(2, 256) (2, 256)\n",
      "(2, 256) (2, 256)\n",
      "(2, 256) (2, 256)\n",
      "(2, 256) (2, 256)\n",
      "(2, 256) (2, 256)\n",
      "(2, 256) (2, 256)\n",
      "(2, 256) (2, 256)\n",
      "\n",
      "Validation loader:\n",
      "(2, 256) (2, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4608, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from previous_chapters import GPTDatasetV1\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "mx.random.seed(123)\n",
    "train_loader = GPTDatasetV1(\n",
    "    train_data,\n",
    "    tokenizer,\n",
    "    GPT_CONFIG_124M[\"context_length\"],\n",
    "    GPT_CONFIG_124M[\"context_length\"],\n",
    "    batch_size=2,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = GPTDatasetV1(\n",
    "    val_data,\n",
    "    tokenizer,\n",
    "    GPT_CONFIG_124M[\"context_length\"],\n",
    "    GPT_CONFIG_124M[\"context_length\"],\n",
    "    batch_size=2,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the trainig loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "    \n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")\n",
    "\n",
    "print(\"Train loader:\")\n",
    "train_tokens = 0\n",
    "for ex in iter(train_loader):\n",
    "    print(ex['input_ids'].shape, ex['target_ids'].shape)\n",
    "    train_tokens += ex['input_ids'].size\n",
    "\n",
    "val_tokens = 0\n",
    "print(\"\\nValidation loader:\")\n",
    "for ex in iter(val_loader):\n",
    "    print(ex['input_ids'].shape, ex['target_ids'].shape)\n",
    "    val_tokens += ex['input_ids'].size\n",
    "\n",
    "train_tokens, val_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f3cad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ce_loss(logits, target):\n",
    "    loss = nn.losses.cross_entropy(logits.flatten(0, 1), target.flatten(), \n",
    "                                   reduction=\"mean\")\n",
    "    return loss\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, no_grad, device=None):\n",
    "    input_batch, target_batch = mx.array(input_batch), mx.array(target_batch)\n",
    "\n",
    "    if no_grad:\n",
    "        input_batch = mx.stop_gradient(input_batch)\n",
    "    logits = model(input_batch)\n",
    "    batch_step_fn = nn.value_and_grad(model, compute_ce_loss)\n",
    "    loss, grad = batch_step_fn(logits, target_batch)\n",
    "    return loss, grad\n",
    "\n",
    "def calc_loss_loader(data_loader, model, no_grad, device=None, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, ex in enumerate(iter(data_loader)):\n",
    "        if i < num_batches:\n",
    "            loss, _ = calc_loss_batch(ex['input_ids'], ex['target_ids'], model, no_grad, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70255990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.026213222079807, 11.002269744873047)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.random.seed(123)\n",
    "train_loss = calc_loss_loader(train_loader, model, True)\n",
    "val_loss = calc_loss_loader(val_loader, model, True)\n",
    "train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad4453",
   "metadata": {},
   "source": [
    "# Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c2c314e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Device(gpu, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: set device for model and data functions\n",
    "mx.default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd156eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, \n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # mx.eval(model.parameters())\n",
    "        model.train()\n",
    "        for batch in iter(train_loader):\n",
    "            input_batch, target_batch = batch['input_ids'], batch['target_ids']\n",
    "            loss, grads = calc_loss_batch(input_batch, target_batch, model, no_grad=False)\n",
    "            optimizer.update(model, grads)\n",
    "            # Force a graph evaluation\n",
    "            # mx.eval(model.parameters(), optimizer.state)\n",
    "            # mx.eval(model.state)\n",
    "            mx.eval(loss, [model.state, optimizer.state])\n",
    "            tokens_seen += input_batch.size\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1}, step {global_step:06d}: \"\n",
    "                      f\"train loss {train_loss:.3f}, val loss {val_loss:.3f}\")\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "        # print(f\"Epoch {epoch+1}, Loss: {loss.item():.3f}, Tokens seen: {tokens_seen}\")\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    train_loss = calc_loss_loader(train_loader, model, True, device, eval_iter)\n",
    "    val_loss = calc_loss_loader(val_loader, model, True, device, eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer)\n",
    "    token_ids = generate_text_simple(\n",
    "        model=model,\n",
    "        idx=mx.stop_gradient(encoded),\n",
    "        max_new_tokens=50,\n",
    "        context_size=context_size,\n",
    "    )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d5ff2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 000005: train loss 11.036, val loss 11.002\n",
      "Every effort moves you DMVSK DMVieversseparSKseparseparseparseparseparseparseparseparSKSKSK hrsSK hrsSKSKSK hrsSKSKSKSKSK hrsSK hrsSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSK\n",
      "Epoch 2, step 000010: train loss 11.034, val loss 11.002\n",
      "Epoch 2, step 000015: train loss 11.031, val loss 11.002\n",
      "Every effort moves you DMVSK DMVieversseparSKseparseparseparseparseparseparseparseparSKSKSK hrsSK hrsSKSKSK hrsSKSKSKSKSK hrsSK hrsSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSK\n",
      "Epoch 3, step 000020: train loss 11.026, val loss 11.002\n",
      "Epoch 3, step 000025: train loss 11.021, val loss 11.002\n",
      "Every effort moves you DMVSK DMVieversseparSKseparseparseparseparseparseparseparseparSKSKSK hrsSK hrsSKSKSK hrsSKSKSKSKSK hrsSK hrsSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSK\n",
      "Epoch 4, step 000030: train loss 11.021, val loss 11.001\n",
      "Epoch 4, step 000035: train loss 11.028, val loss 11.001\n",
      "Every effort moves you DMVSK DMVieversseparSKseparseparseparseparseparseparseparseparSKSKSK hrsSK hrsSKSKSK hrsSKSKSKSKSK hrsSK hrsSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSK\n",
      "Epoch 5, step 000040: train loss 11.004, val loss 11.001\n",
      "Epoch 5, step 000045: train loss 11.032, val loss 11.001\n",
      "Every effort moves you DMVSK DMVieversseparSKseparseparseparseparseparseparseparseparSKSKSK hrsSK hrsSKSKSK hrsSKSKSKSKSK hrsSK hrsSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSK\n",
      "Epoch 6, step 000050: train loss 11.016, val loss 11.001\n",
      "Every effort moves you DMVSK DMVieversseparSKseparseparseparseparseparseparseparseparSKSKSK hrsSK hrsSKSKSK hrsSKSKSKSKSK hrsSK hrsSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSK\n",
      "Epoch 7, step 000055: train loss 11.011, val loss 11.001\n",
      "Epoch 7, step 000060: train loss 11.047, val loss 11.001\n",
      "Every effort moves you DMVSK DMVieversseparSKseparseparseparseparseparseparseparseparSKSKSK hrsSK hrsSKSKSK hrsSKSKSKSKSK hrsSK hrsSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSK\n",
      "Epoch 8, step 000065: train loss 11.009, val loss 11.000\n",
      "Epoch 8, step 000070: train loss 11.039, val loss 11.000\n",
      "Every effort moves you DMVSK DMVieversseparSKseparseparseparseparseparseparseparseparSKSKSK hrsSK hrsSKSKSK hrsSKSKSKSKSK hrsSK hrsSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSK\n",
      "Epoch 9, step 000075: train loss 11.026, val loss 11.000\n",
      "Epoch 9, step 000080: train loss 11.047, val loss 11.000\n",
      "Every effort moves you DMVSK DMVieversseparSKseparseparseparseparseparseparseparseparSKSKSK hrsSK hrsSKSKSK hrsSKSKSKSKSK hrsSK hrsSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSK\n",
      "Epoch 10, step 000085: train loss 11.034, val loss 11.000\n",
      "Epoch 10, step 000090: train loss 11.030, val loss 11.000\n",
      "Every effort moves you DMVSK DMVieversseparSKseparseparseparseparseparseparseparseparSKSKSK hrsSK hrsSKSKSK hrsSKSKSKSKSK hrsSK hrsSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSKSK\n"
     ]
    }
   ],
   "source": [
    "mx.random.seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "optimizer = optim.AdamW(learning_rate=4e-4, weight_decay=1e-1)\n",
    "\n",
    "# TODO: training is too slow, needs investigation.\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, None, \n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74195dd0",
   "metadata": {},
   "source": [
    "# Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b3ed255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output text:\n",
      " Every effort moves you DMVSK DMVieversseparSKseparseparseparseparseparseparseparseparSKSKSK hrsSK hrsSKSKSK hrsSK\n"
     ]
    }
   ],
   "source": [
    "# generating the same text output\n",
    "model.eval()\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "print(\"output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "010ffa02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forward'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temperature scaling and sample from the distribution, instead of using argmax\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# suppose input is \"every effort moves you\", and the LLM returns the following logits for the next token:\n",
    "next_token_logits = mx.array([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])\n",
    "probas = nn.softmax(next_token_logits, axis=-1)\n",
    "next_token_id = mx.argmax(probas).item()\n",
    "inverse_vocab[next_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6965841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.0 x closer\n",
      "87.0 x every\n",
      "98.0 x effort\n",
      "177.0 x forward\n",
      "100.0 x inches\n",
      "93.0 x moves\n",
      "98.0 x pizza\n",
      "137.0 x toward\n",
      "103.0 x you\n"
     ]
    }
   ],
   "source": [
    "mx.random.seed(123)\n",
    "sample = [mx.random.categorical(probas, num_samples=1).item() for _ in range(1000)]\n",
    "sampled_ids = mx.zeros(len(vocab)).at[sample].add(1)\n",
    "for i, freq in enumerate(sampled_ids):\n",
    "    print(f\"{freq} x {inverse_vocab[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature sampling\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return nn.softmax(scaled_logits, axis=0)\n",
    "\n",
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5431cb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "SmallVector out of range.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m fig, ax = plt.subplots(figsize=(\u001b[32m5\u001b[39m, \u001b[32m3\u001b[39m))\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, T \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(temperatures):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     rects = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mbar_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaled_probas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbar_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTemperature=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mT\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m ax.set_ylabel(\u001b[33m'\u001b[39m\u001b[33mProbability\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m ax.set_xticks(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/llms-from-scratch-mlx/.venv/lib/python3.13/site-packages/matplotlib/__init__.py:1524\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1521\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1530\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1531\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/llms-from-scratch-mlx/.venv/lib/python3.13/site-packages/matplotlib/axes/_axes.py:2573\u001b[39m, in \u001b[36mAxes.bar\u001b[39m\u001b[34m(self, x, height, width, bottom, align, **kwargs)\u001b[39m\n\u001b[32m   2571\u001b[39m x0 = x\n\u001b[32m   2572\u001b[39m x = np.asarray(\u001b[38;5;28mself\u001b[39m.convert_xunits(x))\n\u001b[32m-> \u001b[39m\u001b[32m2573\u001b[39m width = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_dx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_xunits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2575\u001b[39m     xerr = \u001b[38;5;28mself\u001b[39m._convert_dx(xerr, x0, x, \u001b[38;5;28mself\u001b[39m.convert_xunits)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/llms-from-scratch-mlx/.venv/lib/python3.13/site-packages/matplotlib/axes/_axes.py:2315\u001b[39m, in \u001b[36mAxes._convert_dx\u001b[39m\u001b[34m(dx, x0, xconv, convert)\u001b[39m\n\u001b[32m   2313\u001b[39m     dx = [dx]\n\u001b[32m   2314\u001b[39m     delist = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2315\u001b[39m dx = [\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mddx\u001b[49m\u001b[43m)\u001b[49m - x \u001b[38;5;28;01mfor\u001b[39;00m ddx \u001b[38;5;129;01min\u001b[39;00m dx]\n\u001b[32m   2316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m delist:\n\u001b[32m   2317\u001b[39m     dx = dx[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/llms-from-scratch-mlx/.venv/lib/python3.13/site-packages/matplotlib/artist.py:278\u001b[39m, in \u001b[36mArtist.convert_xunits\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ax.xaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mxaxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/llms-from-scratch-mlx/.venv/lib/python3.13/site-packages/matplotlib/axis.py:1802\u001b[39m, in \u001b[36mAxis.convert_units\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m   1800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_units\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m   1801\u001b[39m     \u001b[38;5;66;03m# If x is natively supported by Matplotlib, doesn't need converting\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1802\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmunits\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_is_natively_supported\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1803\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1805\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._converter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/llms-from-scratch-mlx/.venv/lib/python3.13/site-packages/matplotlib/units.py:62\u001b[39m, in \u001b[36m_is_natively_supported\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03mReturn whether *x* is of a type that Matplotlib natively supports or an\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[33;03marray of objects of such types.\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Matplotlib natively supports all number types except Decimal.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# Assume lists are homogeneous as other functions in unit system.\u001b[39;00m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m thisx \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thisx \u001b[38;5;129;01mis\u001b[39;00m ma.masked:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/llms-from-scratch-mlx/.venv/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:398\u001b[39m, in \u001b[36miterable\u001b[39m\u001b[34m(y)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    361\u001b[39m \u001b[33;03mCheck whether or not an object can be iterated over.\u001b[39;00m\n\u001b[32m    362\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m \n\u001b[32m    396\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: SmallVector out of range."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAAEYCAYAAADPvfYMAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAFndJREFUeJzt3X9Mlef9//E3PwQ0K9iOCcqwrHb2x6zQgjC0pnFhJdHY+ccypkYYqTqnMx1kq1At1LqKc9aQTCyp1dk/5qRrtGmKwbW0pHGykEJN7KY2lrawpiCsk8OwBYX7k+v6fg8TPFjuI3CA9/OR3JH7Ptd1zn2uHM/rXPd9Xfcd5DiOIwAAKBUc6B0AACCQCEIAgGoEIQBANYIQAKAaQQgAUI0gBACoRhACAFQjCAEAqhGEAADVCEIAgGqug/Ddd9+V5cuXy6xZsyQoKEhee+21r61TU1MjDz30kISHh8vdd98thw8f9nd/AQAIbBB2dXVJYmKilJWVDav8xx9/LMuWLZMlS5bImTNn5Fe/+pWsXbtWTp486c/+AgAwooJu5aLbpkd4/PhxWbFixZBltmzZIpWVlfLBBx/0b/vpT38qly9flqqqKn9fGgCAEREqo6y2tlYyMjIGbMvMzLQ9w6F0d3fbxauvr0+++OIL+eY3v2nDFwCgj+M40tnZaU/NBQcHT5wgbGlpkZiYmAHbzLrH45Evv/xSpk6dekOdkpIS2b59+2jvGgBgAmpubpZvf/vbEycI/VFYWCj5+fn96x0dHTJ79mz75iMjIwO6bwCAwDAdqPj4eLnttttG9HlHPQhjY2OltbV1wDazbgLNV2/QMKNLzTKYqUMQAoBuQSN8imzU5xGmp6dLdXX1gG1vvvmm3Q4AQKC5DsL//ve/dhqEWbzTI8zfTU1N/Yc1s7Oz+8tv2LBBGhsb5cknn5Tz58/L/v375ZVXXpG8vLyRfB8AAIxNEL733nvy4IMP2sUw5/LM30VFRXb9888/7w9F4zvf+Y6dPmF6gWb+4fPPPy8vvfSSHTkKAMCEnkc4lidIo6Ki7KAZzhECgE6eUcoCrjUKAFCNIAQAqEYQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBU8ysIy8rKJCEhQSIiIiQtLU3q6upuWr60tFTuuecemTp1qsTHx0teXp589dVX/u4zAACBC8KKigrJz8+X4uJiaWhokMTERMnMzJRLly75LH/kyBEpKCiw5c+dOycHDx60z/HUU0+NxP4DADC2Qbh3715Zt26d5Obmyv333y/l5eUybdo0OXTokM/yp0+flkWLFsmqVatsL/LRRx+VlStXfm0vEgCAcReEPT09Ul9fLxkZGf97guBgu15bW+uzzsKFC20db/A1NjbKiRMnZOnSpUO+Tnd3t3g8ngELAACjIdRN4fb2dunt7ZWYmJgB2836+fPnfdYxPUFT7+GHHxbHceTatWuyYcOGmx4aLSkpke3bt7vZNQAAxueo0ZqaGtm5c6fs37/fnlM8duyYVFZWyo4dO4asU1hYKB0dHf1Lc3PzaO8mAEApVz3C6OhoCQkJkdbW1gHbzXpsbKzPOk8//bSsWbNG1q5da9cfeOAB6erqkvXr18vWrVvtodXBwsPD7QIAwLjqEYaFhUlycrJUV1f3b+vr67Pr6enpPutcuXLlhrAzYWqYQ6UAAEyYHqFhpk7k5ORISkqKpKam2jmCpodnRpEa2dnZEhcXZ8/zGcuXL7cjTR988EE75/DixYu2l2i2ewMRAIAJE4RZWVnS1tYmRUVF0tLSIklJSVJVVdU/gKapqWlAD3Dbtm0SFBRk//3ss8/kW9/6lg3B5557bmTfCQAAfghyJsDxSTN9Iioqyg6ciYyMDPTuAAAmURZwrVEAgGoEIQBANYIQAKAaQQgAUI0gBACoRhACAFQjCAEAqhGEAADVCEIAgGoEIQBANYIQAKAaQQgAUI0gBACoRhACAFQjCAEAqhGEAADVCEIAgGoEIQBANYIQAKAaQQgAUI0gBACoRhACAFQjCAEAqhGEAADVCEIAgGoEIQBANYIQAKAaQQgAUI0gBACoRhACAFQjCAEAqhGEAADVCEIAgGoEIQBANYIQAKCaX0FYVlYmCQkJEhERIWlpaVJXV3fT8pcvX5ZNmzbJzJkzJTw8XObOnSsnTpzwd58BABgxoW4rVFRUSH5+vpSXl9sQLC0tlczMTLlw4YLMmDHjhvI9PT3ywx/+0D726quvSlxcnHz66acyffr0kXoPAAD4LchxHMdNBRN+CxYskH379tn1vr4+iY+Pl82bN0tBQcEN5U1g/v73v5fz58/LlClT/NpJj8cjUVFR0tHRIZGRkX49BwBgYvOMUha4OjRqenf19fWSkZHxvycIDrbrtbW1Puu8/vrrkp6ebg+NxsTEyLx582Tnzp3S29t763sPAMBYHhptb2+3AWYC7Xpm3fT4fGlsbJS3335bVq9ebc8LXrx4UTZu3ChXr16V4uJin3W6u7vtcv2vAAAAJuSoUXPo1JwffPHFFyU5OVmysrJk69at9pDpUEpKSmz317uYQ68AAAQ8CKOjoyUkJERaW1sHbDfrsbGxPuuYkaJmlKip53XfffdJS0uLPdTqS2FhoT0G7F2am5vd7CYAAKMThGFhYbZXV11dPaDHZ9bNeUBfFi1aZA+HmnJeH374oQ1I83y+mCkW5kTo9QsAAOPi0KiZOnHgwAF5+eWX5dy5c/KLX/xCurq6JDc31z6enZ1te3Re5vEvvvhCnnjiCRuAlZWVdrCMGTwDAMCEm0dozvG1tbVJUVGRPbyZlJQkVVVV/QNompqa7EhSL3N+7+TJk5KXlyfz58+38whNKG7ZsmVk3wkAAGMxjzAQmEcIAPCMh3mEAABMNgQhAEA1ghAAoBpBCABQjSAEAKhGEAIAVCMIAQCqEYQAANUIQgCAagQhAEA1ghAAoBpBCABQjSAEAKhGEAIAVCMIAQCqEYQAANUIQgCAagQhAEA1ghAAoBpBCABQjSAEAKhGEAIAVCMIAQCqEYQAANUIQgCAagQhAEA1ghAAoBpBCABQjSAEAKhGEAIAVCMIAQCqEYQAANUIQgCAagQhAEA1ghAAoBpBCABQza8gLCsrk4SEBImIiJC0tDSpq6sbVr2jR49KUFCQrFixwp+XBQAg8EFYUVEh+fn5UlxcLA0NDZKYmCiZmZly6dKlm9b75JNP5Ne//rUsXrz4VvYXAIDABuHevXtl3bp1kpubK/fff7+Ul5fLtGnT5NChQ0PW6e3tldWrV8v27dvlrrvuutV9BgAgMEHY09Mj9fX1kpGR8b8nCA6267W1tUPWe/bZZ2XGjBny+OOPD+t1uru7xePxDFgAAAh4ELa3t9veXUxMzIDtZr2lpcVnnVOnTsnBgwflwIEDw36dkpISiYqK6l/i4+Pd7CYAAONj1GhnZ6esWbPGhmB0dPSw6xUWFkpHR0f/0tzcPJq7CQBQLNRNYRNmISEh0traOmC7WY+Njb2h/EcffWQHySxfvrx/W19f3/974dBQuXDhgsyZM+eGeuHh4XYBAGBc9QjDwsIkOTlZqqurBwSbWU9PT7+h/L333itnz56VM2fO9C+PPfaYLFmyxP7NIU8AwITqERpm6kROTo6kpKRIamqqlJaWSldXlx1FamRnZ0tcXJw9z2fmGc6bN29A/enTp9t/B28HAGBCBGFWVpa0tbVJUVGRHSCTlJQkVVVV/QNompqa7EhSAAAmgiDHcRwZ58z0CTN61AyciYyMDPTuAAAmURbQdQMAqEYQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBUIwgBAKr5FYRlZWWSkJAgERERkpaWJnV1dUOWPXDggCxevFhuv/12u2RkZNy0PAAA4zoIKyoqJD8/X4qLi6WhoUESExMlMzNTLl265LN8TU2NrFy5Ut555x2pra2V+Ph4efTRR+Wzzz4bif0HAOCWBDmO47ipYHqACxYskH379tn1vr4+G26bN2+WgoKCr63f29tre4amfnZ29rBe0+PxSFRUlHR0dEhkZKSb3QUATBKeUcoCVz3Cnp4eqa+vt4c3+58gONium97ecFy5ckWuXr0qd9xxx5Bluru77Ru+fgEAYDS4CsL29nbbo4uJiRmw3ay3tLQM6zm2bNkis2bNGhCmg5WUlNjU9y6mxwkAwIQfNbpr1y45evSoHD9+3A60GUphYaHt+nqX5ubmsdxNAIAioW4KR0dHS0hIiLS2tg7YbtZjY2NvWnfPnj02CN966y2ZP3/+TcuGh4fbBQCAcdUjDAsLk+TkZKmuru7fZgbLmPX09PQh6+3evVt27NghVVVVkpKScmt7DABAoHqEhpk6kZOTYwMtNTVVSktLpaurS3Jzc+3jZiRoXFycPc9n/O53v5OioiI5cuSInXvoPZf4jW98wy4AAEyoIMzKypK2tjYbbibUkpKSbE/PO4CmqanJjiT1euGFF+xo0x//+McDnsfMQ3zmmWdG4j0AADB28wgDgXmEAADPeJhHCADAZEMQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBUIwgBAKoRhAAA1QhCAIBqBCEAQDWCEACgGkEIAFCNIAQAqEYQAgBUIwgBAKr5FYRlZWWSkJAgERERkpaWJnV1dTct/5e//EXuvfdeW/6BBx6QEydO+Lu/AAAENggrKiokPz9fiouLpaGhQRITEyUzM1MuXbrks/zp06dl5cqV8vjjj8v7778vK1assMsHH3wwEvsPAMAtCXIcx3FTwfQAFyxYIPv27bPrfX19Eh8fL5s3b5aCgoIbymdlZUlXV5e88cYb/du+//3vS1JSkpSXlw/rNT0ej0RFRUlHR4dERka62V0AwCThGaUsCHVTuKenR+rr66WwsLB/W3BwsGRkZEhtba3POma76UFez/QgX3vttSFfp7u72y5e5k17GwEAoJPn/2eAy/7byAZhe3u79Pb2SkxMzIDtZv38+fM+67S0tPgsb7YPpaSkRLZv337DdtPzBADo9u9//9v2DAMShGPF9Div70VevnxZ7rzzTmlqahrRNz/ZfzmZHw7Nzc0cTnaBdnOPNvMP7eaeOTo4e/ZsueOOO2QkuQrC6OhoCQkJkdbW1gHbzXpsbKzPOma7m/JGeHi4XQYzIcgHxh3TXrSZe7Sbe7SZf2g398wpuZHk6tnCwsIkOTlZqqur+7eZwTJmPT093Wcds/368sabb745ZHkAAMaS60Oj5pBlTk6OpKSkSGpqqpSWltpRobm5ufbx7OxsiYuLs+f5jCeeeEIeeeQRef7552XZsmVy9OhRee+99+TFF18c+XcDAMBoB6GZDtHW1iZFRUV2wIuZBlFVVdU/IMacx7u+27pw4UI5cuSIbNu2TZ566in57ne/a0eMzps3b9ivaQ6TmnmLvg6XwjfazD+0m3u0mX9ot/HTZq7nEQIAMJlwrVEAgGoEIQBANYIQAKAaQQgAUG3cBCG3dhrdNjtw4IAsXrxYbr/9druY68N+XRtPVm4/a15m6k9QUJC9e4o2btvMXA1q06ZNMnPmTDvCb+7cufwfHUa7melo99xzj0ydOtVedSYvL0+++uor0eLdd9+V5cuXy6xZs+z/tZtdk9qrpqZGHnroIfs5u/vuu+Xw4cPuX9gZB44ePeqEhYU5hw4dcv7xj38469atc6ZPn+60trb6LP+3v/3NCQkJcXbv3u3885//dLZt2+ZMmTLFOXv2rKOF2zZbtWqVU1ZW5rz//vvOuXPnnJ/97GdOVFSU869//cvRxG27eX388cdOXFycs3jxYudHP/qRo4nbNuvu7nZSUlKcpUuXOqdOnbJtV1NT45w5c8bRxG27/elPf3LCw8Ptv6bNTp486cycOdPJy8tztDhx4oSzdetW59ixY2Y2g3P8+PGblm9sbHSmTZvm5Ofn2yz4wx/+YLOhqqrK1euOiyBMTU11Nm3a1L/e29vrzJo1yykpKfFZ/ic/+YmzbNmyAdvS0tKcn//8544WbttssGvXrjm33Xab8/LLLzua+NNupq0WLlzovPTSS05OTo66IHTbZi+88IJz1113OT09PY5mbtvNlP3BD34wYJv5gl+0aJGjkQwjCJ988knne9/73oBtWVlZTmZmpqvXCvihUe+tncyhOje3drq+vPfWTkOVn2z8abPBrly5IlevXh3xi9dOxnZ79tlnZcaMGfbm0tr402avv/66vYSiOTRqLrRhLp6xc+dOe+caLfxpN3PxEVPHe/i0sbHRHk5eunTpmO33RDNSWRDwu0+M1a2dJhN/2mywLVu22OPwgz9Ek5k/7Xbq1Ck5ePCgnDlzRjTyp83MF/jbb78tq1evtl/kFy9elI0bN9ofXuaqIBr4026rVq2y9R5++GF7v71r167Jhg0b7BW5IK6ywNzZ48svv7TnWocj4D1CjL1du3bZgR/Hjx+3J/HhW2dnp6xZs8YONDJ3XsHwmAvxmx60uZ6wuUi/uSzj1q1bpby8PNC7Nq6ZQR+m57x//35paGiQY8eOSWVlpezYsSPQuzbpBbxHOFa3dppM/Gkzrz179tggfOutt2T+/Pmiidt2++ijj+STTz6xo9iu/5I3QkND5cKFCzJnzhyZzPz5rJmRolOmTLH1vO677z77690cMjR3sZns/Gm3p59+2v7wWrt2rV03o+HNDQ3Wr19vf0iM9K2HJoPYIbLA3NZquL1BI+Aty62dxqbNjN27d9tfl+Yi6ebuIdq4bTczPefs2bP2sKh3eeyxx2TJkiX2bzO8fbLz57O2aNEiezjU+6PB+PDDD21AaghBf9vNnLcfHHbeHxNcElpGNwuccTLM2AwbPnz4sB0Cu379ejvMuKWlxT6+Zs0ap6CgYMD0idDQUGfPnj12KkBxcbHK6RNu2mzXrl12KPerr77qfP755/1LZ2eno4nbdhtM46hRt23W1NRkRyT/8pe/dC5cuOC88cYbzowZM5zf/va3jiZu2818j5l2+/Of/2ynBfz1r3915syZY0fJa9HZ2WmneJnFxNPevXvt359++ql93LSXabfB0yd+85vf2CwwU8Qm7PQJw8z/mD17tv2yNsOO//73v/c/9sgjj9gvoOu98sorzty5c215M3y2srLS0cZNm9155532gzV4Mf/5tHH7WdMehP602enTp+2UJhMEZirFc889Z6ehaOOm3a5eveo888wzNvwiIiKc+Ph4Z+PGjc5//vMfR4t33nnH5/eUt53Mv6bdBtdJSkqybWw+a3/84x9dvy63YQIAqBbwc4QAAAQSQQgAUI0gBACoRhACAFQjCAEAqhGEAADVCEIAgGoEIQBANYIQAKAaQQgAUI0gBACoRhACAESz/wOC7PdCXGWl+AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = mx.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature={T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f50edcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.51, 6.28, 6.75], dtype=float32), array([3, 7, 0], dtype=uint32))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top-k sampling\n",
    "top_k = 3\n",
    "top_logits = mx.topk(next_token_logits, top_k)\n",
    "top_pos = mx.argsort(next_token_logits)[::-1][:top_k]\n",
    "top_logits, top_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "743dd5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.51, -inf, -inf, ..., -inf, 6.28, -inf], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_logits = mx.where(\n",
    "    next_token_logits < top_logits.min(),\n",
    "    -mx.inf,\n",
    "    next_token_logits,\n",
    ")\n",
    "new_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11f409a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated generation function with temperature and top-k sampling\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        logits = model(mx.stop_gradient(idx_cond))\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # top_k filtering\n",
    "        if top_k is not None:\n",
    "            top_logits = mx.topk(logits, top_k)\n",
    "            min_val = top_logits.min()\n",
    "            logits = mx.where(logits < min_val, -mx.inf, logits)\n",
    "        \n",
    "        # temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = mx.softmax(logits, axis=-1)\n",
    "            idx_next = mx.random.categorical(probs, num_samples=1)\n",
    "        # otherwise, use the highest logit value\n",
    "        else:\n",
    "            idx_next = mx.argmax(logits, axis=-1, keepdims=True)\n",
    "\n",
    "        if idx_next.item() == eos_id:\n",
    "            break\n",
    "        idx = mx.concat([idx, idx_next], axis=1)\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e2833e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you783 hallmark Cherpass indicator identifies sector lair riteictionaryAlong Hampshirelaughs sons mocked\n"
     ]
    }
   ],
   "source": [
    "mx.random.seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4,\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ed49b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-from-scratch-mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
