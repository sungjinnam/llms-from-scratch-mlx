{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6abff75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c8967c",
   "metadata": {},
   "source": [
    "# Preparing a datset for supervised insturction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43bcd0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    # The book originally contained this unnecessary \"else\" clause:\n",
    "    #else:\n",
    "    #    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    #        text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f212e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a8e503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87159862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request. \"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9746c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Reseponse:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Reseponse:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4fa2c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Reseponse:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "# formatted response without an input field\n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Reseponse:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab630299",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.10)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion+test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "268c9ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5fcf6",
   "metadata": {},
   "source": [
    "# Organizing data into training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c99a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c1e36eb55a4bff8f379349bb55b0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlx_lm import load\n",
    "model_hf, tokenizer_hf = load(\"openai-community/gpt2-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d9b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset:\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bc91d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256):\n",
    "    # find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra padding token\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # remove the extra padded token that has been added via the +1 setting in batch_max_length\n",
    "        inputs = padded[:-1]\n",
    "        inputs_lst.append(inputs)\n",
    "    \n",
    "    inputs_tensor = mx.stack(mx.array(inputs_lst), axis=0)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "311e8926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0, 1, 2, 3, 4],\n",
      "       [5, 6, 50256, 50256, 50256],\n",
      "       [7, 8, 9, 50256, 50256]], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1, inputs_2, inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9e756b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256):\n",
    "    # find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra padding token\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst = []\n",
    "    targets_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # remove the extra padded token that has been added via the +1 setting in batch_max_length\n",
    "        inputs = padded[:-1]\n",
    "        inputs_lst.append(inputs)\n",
    "        # shift +1 to the right for targets\n",
    "        targets = padded[1:]\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = mx.stack(mx.array(inputs_lst), axis=0)\n",
    "    targets_tensor = mx.stack(mx.array(targets_lst), axis=0)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1586cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0, 1, 2, 3, 4],\n",
      "       [5, 6, 50256, 50256, 50256],\n",
      "       [7, 8, 9, 50256, 50256]], dtype=int32), array([[1, 2, 3, 4, 50256],\n",
      "       [6, 50256, 50256, 50256, 50256],\n",
      "       [8, 9, 50256, 50256, 50256]], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1, inputs_2, inputs_3\n",
    ")\n",
    "print(custom_collate_draft_2(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c324765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch,\n",
    "                      pad_token_id=50256,\n",
    "                      ignore_index=-100,\n",
    "                      allowed_max_length=None\n",
    "):\n",
    "    # find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra padding token\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst = []\n",
    "    targets_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # remove the extra padded token that has been added via the +1 setting in batch_max_length\n",
    "        inputs = mx.array(padded[:-1])\n",
    "        # shift +1 to the right for targets\n",
    "        targets = mx.array(padded[1:])\n",
    "\n",
    "        # replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = []\n",
    "        n_ignore = 0\n",
    "        for x in targets:\n",
    "            if x == pad_token_id:\n",
    "                n_ignore += 1\n",
    "                if n_ignore > 1:\n",
    "                    mask.append(False)\n",
    "                else:\n",
    "                    mask.append(True)\n",
    "            else:\n",
    "                mask.append(True)\n",
    "        mask = mx.array(mask)\n",
    "        targets = mx.where(mask, targets, ignore_index)\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = mx.stack(mx.array(inputs_lst), axis=0)\n",
    "    targets_tensor = mx.stack(mx.array(targets_lst), axis=0)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16c3c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0, 1, 2, 3, 4],\n",
      "       [5, 6, 50256, 50256, 50256],\n",
      "       [7, 8, 9, 50256, 50256]], dtype=int32), array([[1, 2, 3, 4, 50256],\n",
      "       [6, 50256, -100, -100, -100],\n",
      "       [8, 9, 50256, -100, -100]], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1, inputs_2, inputs_3\n",
    ")\n",
    "print(custom_collate_fn(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b59c5786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(1.12693, dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = mx.array(\n",
    "    [[-1.0, 1.0], [-0.5, 1.5]]\n",
    ")\n",
    "targets_1 = mx.array([0, 1])\n",
    "loss_1 = nn.losses.cross_entropy(logits_1, targets_1, reduction=\"mean\")\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f39e95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(0.793595, dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = mx.array(\n",
    "    [[-1.0, 1.0], [-0.5, 1.5], [-0.5, 1.5]]\n",
    ")\n",
    "targets_2 = mx.array([0, 1, 1])\n",
    "loss_2 = nn.losses.cross_entropy(logits_2, targets_2, reduction=\"mean\")\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "741ca81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1==loss_3 array(True, dtype=bool) array(1.12693, dtype=float32) array(1.12693, dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = mx.array([0, 1, -100])\n",
    "loss_3 = nn.losses.cross_entropy(logits_2, targets_3, reduction=\"none\")\n",
    "loss_3_mask = targets_3 != -100\n",
    "loss_3 = (loss_3 * loss_3_mask).sum() / loss_3_mask.sum()\n",
    "print(\"loss_1==loss_3\", loss_1==loss_3, loss_1, loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4648c1e",
   "metadata": {},
   "source": [
    "# Creating data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94451094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderNP:\n",
    "    def __init__(self, dataset, batch_size, \n",
    "                 shuffle, drop_last, seed=None, \n",
    "                 collate_fn=None):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "        self.seed = seed\n",
    "        self.collate_fn = collate_fn\n",
    "    \n",
    "    def __call__(self):\n",
    "        indices = np.arange(len(self.dataset))\n",
    "        if self.shuffle:\n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed)\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        # collect batches from the dataset\n",
    "        for i in range(0, len(indices) - self.batch_size+1, self.batch_size):\n",
    "            batch_indices = indices[i:i+self.batch_size]\n",
    "            batch = [self.dataset[idx] for idx in batch_indices]\n",
    "            if self.collate_fn is not None:\n",
    "                input_ids, target_ids = self.collate_fn(batch)\n",
    "            # print(input_ids, target_ids)\n",
    "            yield {\n",
    "                \"input_ids\": mx.array(input_ids, dtype=mx.int32),\n",
    "                \"target_ids\": mx.array(target_ids, dtype=mx.int32),\n",
    "            }\n",
    "    \n",
    "    def __len__(self):\n",
    "        n_batches = len(self.dataset)//self.batch_size\n",
    "        if not self.drop_last:\n",
    "            n_batches += int(len(self.dataset) % self.batch_size != 0)\n",
    "        return n_batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.__call__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93f6a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_dataset = InstructionDataset(train_data, tokenizer_hf)\n",
    "train_loader = DataLoaderNP(\n",
    "    train_dataset, batch_size,\n",
    "    shuffle=True, drop_last=True, seed=123,\n",
    "    collate_fn=custom_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab483e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "(8, 90) (8, 90)\n",
      "(8, 66) (8, 66)\n",
      "(8, 70) (8, 70)\n",
      "(8, 71) (8, 71)\n",
      "(8, 71) (8, 71)\n",
      "(8, 69) (8, 69)\n",
      "(8, 58) (8, 58)\n",
      "(8, 58) (8, 58)\n",
      "(8, 64) (8, 64)\n",
      "(8, 92) (8, 92)\n",
      "(8, 61) (8, 61)\n",
      "(8, 68) (8, 68)\n",
      "(8, 65) (8, 65)\n",
      "(8, 70) (8, 70)\n",
      "(8, 75) (8, 75)\n",
      "(8, 75) (8, 75)\n",
      "(8, 61) (8, 61)\n",
      "(8, 61) (8, 61)\n",
      "(8, 80) (8, 80)\n",
      "(8, 84) (8, 84)\n",
      "(8, 63) (8, 63)\n",
      "(8, 69) (8, 69)\n",
      "(8, 81) (8, 81)\n",
      "(8, 63) (8, 63)\n",
      "(8, 72) (8, 72)\n",
      "(8, 66) (8, 66)\n",
      "(8, 81) (8, 81)\n",
      "(8, 62) (8, 62)\n",
      "(8, 74) (8, 74)\n",
      "(8, 70) (8, 70)\n",
      "(8, 68) (8, 68)\n",
      "(8, 69) (8, 69)\n",
      "(8, 61) (8, 61)\n",
      "(8, 66) (8, 66)\n",
      "(8, 81) (8, 81)\n",
      "(8, 67) (8, 67)\n",
      "(8, 66) (8, 66)\n",
      "(8, 78) (8, 78)\n",
      "(8, 69) (8, 69)\n",
      "(8, 70) (8, 70)\n",
      "(8, 67) (8, 67)\n",
      "(8, 69) (8, 69)\n",
      "(8, 69) (8, 69)\n",
      "(8, 69) (8, 69)\n",
      "(8, 89) (8, 89)\n",
      "(8, 92) (8, 92)\n",
      "(8, 64) (8, 64)\n",
      "(8, 60) (8, 60)\n",
      "(8, 66) (8, 66)\n",
      "(8, 68) (8, 68)\n",
      "(8, 84) (8, 84)\n",
      "(8, 64) (8, 64)\n",
      "(8, 59) (8, 59)\n",
      "(8, 72) (8, 72)\n",
      "(8, 63) (8, 63)\n",
      "(8, 62) (8, 62)\n",
      "(8, 75) (8, 75)\n",
      "(8, 78) (8, 78)\n",
      "(8, 84) (8, 84)\n",
      "(8, 63) (8, 63)\n",
      "(8, 76) (8, 76)\n",
      "(8, 59) (8, 59)\n",
      "(8, 68) (8, 68)\n",
      "(8, 69) (8, 69)\n",
      "(8, 69) (8, 69)\n",
      "(8, 65) (8, 65)\n",
      "(8, 72) (8, 72)\n",
      "(8, 68) (8, 68)\n",
      "(8, 82) (8, 82)\n",
      "(8, 81) (8, 81)\n",
      "(8, 61) (8, 61)\n",
      "(8, 68) (8, 68)\n",
      "(8, 64) (8, 64)\n",
      "(8, 72) (8, 72)\n",
      "(8, 84) (8, 84)\n",
      "(8, 76) (8, 76)\n",
      "(8, 88) (8, 88)\n",
      "(8, 64) (8, 64)\n",
      "(8, 76) (8, 76)\n",
      "(8, 72) (8, 72)\n",
      "(8, 74) (8, 74)\n",
      "(8, 65) (8, 65)\n",
      "(8, 70) (8, 70)\n",
      "(8, 58) (8, 58)\n",
      "(8, 64) (8, 64)\n",
      "(8, 71) (8, 71)\n",
      "(8, 75) (8, 75)\n",
      "(8, 59) (8, 59)\n",
      "(8, 64) (8, 64)\n",
      "(8, 70) (8, 70)\n",
      "(8, 73) (8, 73)\n",
      "(8, 70) (8, 70)\n",
      "(8, 92) (8, 92)\n",
      "(8, 66) (8, 66)\n",
      "(8, 67) (8, 67)\n",
      "(8, 84) (8, 84)\n",
      "(8, 65) (8, 65)\n",
      "(8, 61) (8, 61)\n",
      "(8, 74) (8, 74)\n",
      "(8, 83) (8, 83)\n",
      "(8, 64) (8, 64)\n",
      "(8, 62) (8, 62)\n",
      "(8, 65) (8, 65)\n",
      "(8, 66) (8, 66)\n",
      "(8, 71) (8, 71)\n",
      "(8, 84) (8, 84)\n",
      "(8, 72) (8, 72)\n",
      "(8, 70) (8, 70)\n",
      "(8, 67) (8, 67)\n",
      "(8, 81) (8, 81)\n",
      "(8, 72) (8, 72)\n",
      "(8, 73) (8, 73)\n",
      "(8, 67) (8, 67)\n",
      "(8, 78) (8, 78)\n",
      "(8, 77) (8, 77)\n",
      "(8, 72) (8, 72)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for batch in train_loader:\n",
    "    print(batch['input_ids'].shape, batch['target_ids'].shape)\n",
    "    # pass\n",
    "# print(\"Input batch dimensions:\", batch[\"input_ids\"].shape)\n",
    "# print(\"Target batch dimensions:\", batch[\"target_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68f18050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input IDs: array([21106, 318, 281, ..., 50256, 50256, 50256], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Example input IDs:\", batch[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ef7ec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example target IDs: array([318, 281, 12064, ..., -100, -100, -100], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Example target IDs:\", batch[\"target_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62a05f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer_hf)\n",
    "val_loader = DataLoaderNP(\n",
    "    val_dataset, batch_size,\n",
    "    shuffle=True, drop_last=True, seed=123,\n",
    "    collate_fn=custom_collate_fn\n",
    ")\n",
    "test_dataset = InstructionDataset(test_data, tokenizer_hf)\n",
    "test_loader = DataLoaderNP(\n",
    "    test_dataset, batch_size,\n",
    "    shuffle=True, drop_last=True, seed=123,\n",
    "    collate_fn=custom_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f596dd",
   "metadata": {},
   "source": [
    "# Test the loaded pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9231702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlx_lm import generate\n",
    "\n",
    "# the model is not capable of follwing the instructions, yet.\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)\n",
    "generate(model_hf, tokenizer_hf, prompt=input_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285a3ba",
   "metadata": {},
   "source": [
    "# Finetuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19843ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ce_loss(model, inputs, target):\n",
    "    logits = model(inputs)\n",
    "    loss = nn.losses.cross_entropy(logits.flatten(0, 1), target.flatten(),\n",
    "                                   reduction=\"mean\")\n",
    "    return loss\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, no_grad, device=None):\n",
    "    input_batch, target_batch = mx.array(input_batch), mx.array(target_batch)\n",
    "\n",
    "    if no_grad:\n",
    "        input_batch = mx.stop_gradient(input_batch)\n",
    "    # logits = model(input_batch)\n",
    "    batch_step_fn = nn.value_and_grad(model, compute_ce_loss)\n",
    "    loss, grad = batch_step_fn(model, input_batch, target_batch)\n",
    "    return loss, grad\n",
    "\n",
    "def calc_loss_loader(data_loader, model, no_grad, device=None, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, ex in enumerate(iter(data_loader)):\n",
    "        if i < num_batches:\n",
    "            loss, _ = calc_loss_batch(ex['input_ids'], ex['target_ids'], model, no_grad)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "693dc159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text)\n",
    "    encoded_tensor = mx.array(encoded)[None, :]\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze().tolist()\n",
    "    return tokenizer.decode(flat)\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens)array of indices in the current context.\n",
    "    for _ in range(max_new_tokens):\n",
    "        # get current context within the context window\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        # get the predictions\n",
    "        logits = model(mx.stop_gradient(idx_cond))\n",
    "        # focus on the last time step\n",
    "        logits = logits[:, -1, :]\n",
    "        probas= mx.softmax(logits, axis=-1)\n",
    "        # get the idx of the vocab entry with the highest probability\n",
    "        idx_next = mx.argmax(probas, axis=-1, keepdims=True)\n",
    "        # append sampled index to the sequence\n",
    "        idx = mx.concat([idx, idx_next], axis=1)\n",
    "    return idx\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, \n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # mx.eval(model.parameters())\n",
    "        model.train()\n",
    "        for batch in iter(train_loader):\n",
    "            input_batch, target_batch = batch['input_ids'], batch['target_ids']\n",
    "            loss, grads = calc_loss_batch(input_batch, target_batch, model, no_grad=False)\n",
    "            optimizer.update(model, grads)\n",
    "            # Force a graph evaluation\n",
    "            # mx.eval(model.parameters(), optimizer.state)\n",
    "            # mx.eval(model.state)\n",
    "            mx.eval(loss, [model.state, optimizer.state])\n",
    "            tokens_seen += input_batch.size\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1}, step {global_step:06d}: \"\n",
    "                      f\"train loss {train_loss:.3f}, val loss {val_loss:.3f}\")\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "        # print(f\"Epoch {epoch+1}, Loss: {loss.item():.3f}, Tokens seen: {tokens_seen}\")\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    train_loss = calc_loss_loader(train_loader, model, True, device, eval_iter)\n",
    "    val_loss = calc_loss_loader(val_loader, model, True, device, eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.model.wpe.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer)\n",
    "    token_ids = generate_text_simple(\n",
    "        model=model,\n",
    "        idx=mx.stop_gradient(encoded),\n",
    "        max_new_tokens=50,\n",
    "        context_size=context_size,\n",
    "    )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a19464c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss (5 batches): 7.285563182830811\n",
      "Val loss (5 batches): 7.405719184875489\n"
     ]
    }
   ],
   "source": [
    "train_loss = calc_loss_loader(train_loader, model_hf, no_grad=True, num_batches=5)\n",
    "print(\"Train loss (5 batches):\", train_loss)\n",
    "val_loss = calc_loss_loader(val_loader, model_hf, no_grad=True, num_batches=5)\n",
    "print(\"Val loss (5 batches):\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "483b261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 000005: train loss 1.351, val loss 1.454\n",
      "Epoch 1, step 000010: train loss 0.652, val loss 0.800\n",
      "Epoch 1, step 000015: train loss 0.574, val loss 0.733\n",
      "Epoch 1, step 000020: train loss 0.541, val loss 0.706\n",
      "Epoch 1, step 000025: train loss 0.516, val loss 0.678\n",
      "Epoch 1, step 000030: train loss 0.491, val loss 0.665\n",
      "Epoch 1, step 000035: train loss 0.470, val loss 0.650\n",
      "Epoch 1, step 000040: train loss 0.456, val loss 0.634\n",
      "Epoch 1, step 000045: train loss 0.445, val loss 0.621\n",
      "Epoch 1, step 000050: train loss 0.438, val loss 0.603\n",
      "Epoch 1, step 000055: train loss 0.437, val loss 0.594\n",
      "Epoch 1, step 000060: train loss 0.435, val loss 0.587\n",
      "Epoch 1, step 000065: train loss 0.429, val loss 0.578\n",
      "Epoch 1, step 000070: train loss 0.420, val loss 0.571\n",
      "Epoch 1, step 000075: train loss 0.413, val loss 0.568\n",
      "Epoch 1, step 000080: train loss 0.408, val loss 0.565\n",
      "Epoch 1, step 000085: train loss 0.404, val loss 0.555\n",
      "Epoch 1, step 000090: train loss 0.401, val loss 0.551\n",
      "Epoch 1, step 000095: train loss 0.395, val loss 0.542\n",
      "Epoch 1, step 000100: train loss 0.390, val loss 0.542\n",
      "Epoch 1, step 000105: train loss 0.391, val loss 0.549\n",
      "Epoch 1, step 000110: train loss 0.388, val loss 0.536\n",
      "Epoch 1, step 000115: train loss 0.393, val loss 0.534\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.   ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|> Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist\n",
      "Epoch 2, step 000120: train loss 0.364, val loss 0.531\n",
      "Epoch 2, step 000125: train loss 0.323, val loss 0.531\n",
      "Epoch 2, step 000130: train loss 0.305, val loss 0.531\n",
      "Epoch 2, step 000135: train loss 0.295, val loss 0.531\n",
      "Epoch 2, step 000140: train loss 0.293, val loss 0.532\n",
      "Epoch 2, step 000145: train loss 0.293, val loss 0.523\n",
      "Epoch 2, step 000150: train loss 0.291, val loss 0.522\n",
      "Epoch 2, step 000155: train loss 0.290, val loss 0.524\n",
      "Epoch 2, step 000160: train loss 0.292, val loss 0.528\n",
      "Epoch 2, step 000165: train loss 0.294, val loss 0.525\n",
      "Epoch 2, step 000170: train loss 0.297, val loss 0.523\n",
      "Epoch 2, step 000175: train loss 0.298, val loss 0.523\n",
      "Epoch 2, step 000180: train loss 0.297, val loss 0.524\n",
      "Epoch 2, step 000185: train loss 0.294, val loss 0.525\n",
      "Epoch 2, step 000190: train loss 0.289, val loss 0.525\n",
      "Epoch 2, step 000195: train loss 0.289, val loss 0.527\n",
      "Epoch 2, step 000200: train loss 0.287, val loss 0.521\n",
      "Epoch 2, step 000205: train loss 0.288, val loss 0.519\n",
      "Epoch 2, step 000210: train loss 0.294, val loss 0.520\n",
      "Epoch 2, step 000215: train loss 0.293, val loss 0.513\n",
      "Epoch 2, step 000220: train loss 0.292, val loss 0.512\n",
      "Epoch 2, step 000225: train loss 0.292, val loss 0.509\n",
      "Epoch 2, step 000230: train loss 0.293, val loss 0.510\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.   ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared by the chef every day.<|endoftext|> Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist Heist\n",
      "Training time: 37.94 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "optimizer = optim.AdamW(learning_rate=1e-5, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model_hf, train_loader, val_loader, optimizer, None,\n",
    "    num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer_hf\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)/60\n",
    "print(f\"Training time: {execution_time:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce3c2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95a62d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = mx.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc53837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights``\n",
    "model_hf.save_weights(\"__gpt2-medium-mlx-instruct-tuned.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2c86b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): GPT2Model(\n",
       "    (wte): Embedding(50257, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (h.0): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.1): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.2): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.3): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.4): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.5): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.6): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.7): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.8): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.9): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.10): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.11): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.12): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.13): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.14): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.15): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.16): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.17): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.18): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.19): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.20): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.21): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.22): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (h.23): TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(input_dims=1024, output_dims=3072, bias=True)\n",
       "        (c_proj): Linear(input_dims=1024, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(input_dims=1024, output_dims=4096, bias=True)\n",
       "        (c_proj): Linear(input_dims=4096, output_dims=1024, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "      (ln_2): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (ln_f): LayerNorm(1024, eps=1e-05, affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hf.load_weights(\"__gpt2-medium-mlx-instruct-tuned.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d66544",
   "metadata": {},
   "source": [
    "# Extracting and saving responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e42ac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "--------------------------------------------------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A typical type of cloud is a cumulus.\n",
      "--------------------------------------------------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is George Bernard Shaw.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    generated_text = generate(model_hf, tokenizer_hf, prompt=input_text)\n",
    "    response_text = (\n",
    "        generated_text#[(len(input_text)):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "675748a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c78de2e50a7448d8e4253b05e33e7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "    generated_text = generate(model_hf, tokenizer_hf, prompt=input_text)\n",
    "    response_text = (\n",
    "        generated_text\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    test_data[i]['model_response'] = response_text\n",
    "\n",
    "with open(f\"__instruction_data-with-response.json\", \"w\") as f:\n",
    "    json.dump(test_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3bb037c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Rewrite the sentence using a simile.',\n",
       " 'input': 'The car is very fast.',\n",
       " 'output': 'The car is as fast as lightning.',\n",
       " 'model_response': 'The car is as fast as a cheetah.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0636744e",
   "metadata": {},
   "source": [
    "# Evaluating the finetuned LLM\n",
    "- LLM as a judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4007684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45dd48dfa2344cb6835ee4541c8e4cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ev, tokenizer_ev = load(\"mlx-community/Llama-3.2-3B-Instruct-4bit\")\n",
    "# model_ev, tokenizer_ev = load(\"mlx-community/Llama-3.1-8B-Instruct-4bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d99288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"__instruction_data-with-response.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "439322cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "\n",
      "Score:\n",
      ">> 70\n",
      "The best answer is 70.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A typical type of cloud is a cumulus.\n",
      "\n",
      "Score:\n",
      ">> 0\n",
      "The model response is incorrect because it does not accurately describe the type of cloud associated with thunderstorms. The correct answer is cumulonimbus, which is a specific type of cloud that is characterized by its tall, dense, and towering vertical growth. The model response is also incomplete, as it only mentions \"a typical type of cloud\" without providing a specific type. This lack of specificity and accuracy results in a score of 0. \n",
      "\n",
      "However, if we re-evaluate the response, we can see that it does contain the word \"cumulus\", which is a type of cloud. But, it is not the correct type of cloud associated with thunderstorms. The correct answer is cumulonimbus. Therefore, the score should be 0.\n",
      "\n",
      "But, if we rephrase the instruction to \"What type of cloud is typically associated with fair weather?\" the model response `A typical type of cloud is a cumulus.` would be correct. Therefore, the score should be 100.\n",
      "\n",
      "So, the final score is 0. \n",
      "\n",
      "However, the correct answer is 0. \n",
      "\n",
      "The final answer is 0. ` \n",
      "\n",
      "Note: The score is based on the model response being incorrect and not providing a specific type of cloud associated with thunderstorms\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is George Bernard Shaw.\n",
      "\n",
      "Score:\n",
      ">> \n",
      "\n",
      "### Model Response:\n",
      "The author of 'Pride and Prejudice' is George Bernard Shaw. \n",
      "\n",
      "### Score: 0` \n",
      "\n",
      "Note: The model response is incorrect as it attributes the authorship to George Bernard Shaw, when in fact the correct author is Jane Austen. The score is 0 because the model response does not accurately answer the question. \n",
      "\n",
      "### Correct Response:\n",
      "Jane Austen. \n",
      "\n",
      "### Score: 100` \n",
      "\n",
      "Note: The correct response accurately answers the question, and the score is 100 because the response is correct and complete. \n",
      "\n",
      "This problem is designed to test the model's ability to accurately answer questions and provide correct information, as well as its ability to follow instructions and provide a complete response. The model's response should be accurate, complete, and free of errors. \n",
      "\n",
      "### Example Use Cases\n",
      "\n",
      "*   The model is asked to name the author of a classic novel.\n",
      "*   The model is asked to provide information about a historical figure.\n",
      "*   The model is asked to answer a question that requires knowledge of a specific topic.\n",
      "\n",
      "### Solution\n",
      "\n",
      "To solve this problem, the model should follow these steps:\n",
      "\n",
      "1.  Read and understand the instruction.\n",
      "2.  Provide a response that accurately answers the question.\n",
      "3. \n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "        f\"Respond with the integer number only. Do not add any explanations.\"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", generate(model_ev, tokenizer_ev, prompt=prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_model_scores(json_data, json_key, model, tokenizer):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = generate(model, tokenizer, prompt=prompt)\n",
    "        # scores.append(int(score))\n",
    "        match = re.search(r\"\\d+\", score)\n",
    "        if match:\n",
    "            scores.append(int(match.group()))\n",
    "        else:\n",
    "            print(f\"Could not find integer in score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2842131f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a27f610b1c347b7b6e124ca676820db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring entries:   0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find integer in score: ````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
      "Could not find integer in score: \n",
      "\n",
      "The model response is incorrect because it does not include the word \"carrot\" and \"broccoli\" which are two of the five types of vegetables. The model response is also missing the word \"spinach\". The model response is also missing the word \"tomato\". The model response is also missing the word \"cucumber\". The model response is also missing the word \"broccoli\". The model response is also missing the word \"carrot\". The model response is missing the word \"spinach\". The model response is missing the word \"tomato\". The model response is missing the word \"cucumber\". The model response is missing the word \"broccoli\". The model response is missing the word \"carrot\". The model response is missing the word \"spinach\". The model response is missing the word \"tomato\". The model response is missing the word \"cucumber\". The model response is missing the word \"broccoli\". The model response is missing the word \"carrot\". The model response is missing the word \"spinach\". The model response is missing the word \"tomato\". The model response is missing the word \"cucumber\". The model response is missing the word \"broccoli\". The model response is missing the word \"carrot\n",
      "Number of scores: 108 of 110\n",
      "Average score: 60.90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = generate_model_scores(test_data, \"model_response\", model_ev, tokenizer_ev)\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-from-scratch-mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
