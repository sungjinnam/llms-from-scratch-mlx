{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31915df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import mlx.data as dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7dcac",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d3a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"__sms_spam_collection.zip\"\n",
    "extracted_path = \"__sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd80fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb237fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc95cad",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee8919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe02d0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729c6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e317e",
   "metadata": {},
   "source": [
    "# Creating data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a1f54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "# print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5a0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0df377c6dea4398a70b420eea3c6f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlx_lm import load\n",
    "model_hf, tokenizer_hf = load(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53f68618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset:\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # truncate if longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "        \n",
    "        # pad to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            mx.array(encoded, dtype=mx.int32),\n",
    "            mx.array(label, dtype=mx.int32),\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        # max_length = 0\n",
    "        # for encoded_text in self.encoded_texts:\n",
    "        #     encoded_length = len(encoded_text)\n",
    "        #     if encoded_length > max_length:\n",
    "        #         max_length = encoded_length\n",
    "        # return max_length\n",
    "        return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcca6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer_hf\n",
    ")\n",
    "train_dataset.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cd88668",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer_hf\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer_hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d204f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: (8, 120)\n",
      "Label batch dimensions: array([0, 0, 0, ..., 0, 0, 0], dtype=int32) (8,)\n"
     ]
    }
   ],
   "source": [
    "class DataLoaderNP:\n",
    "    def __init__(self, dataset, batch_size, shuffle, drop_last, seed=None):\n",
    "        self.dataset = [{\"input_ids\": x[0], \"label\": x[1]} for x in dataset]\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "        self.seed = seed\n",
    "    \n",
    "    def __call__(self):\n",
    "        indices = np.arange(len(self.dataset))\n",
    "        if self.shuffle:\n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed)\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        # collect batches from the dataset\n",
    "        for i in range(0, len(indices) - self.batch_size+1, self.batch_size):\n",
    "            batch_indices = indices[i:i+self.batch_size]\n",
    "            batch = [self.dataset[idx] for idx in batch_indices]\n",
    "            input_ids = np.array([item[\"input_ids\"] for item in batch])\n",
    "            labels = np.array([item[\"label\"] for item in batch])\n",
    "            yield {\n",
    "                \"input_ids\": mx.array(input_ids, dtype=mx.int32),\n",
    "                \"label\": mx.array(labels, dtype=mx.int32),\n",
    "            }\n",
    "    \n",
    "    def __len__(self):\n",
    "        n_batches = len(self.dataset)//self.batch_size\n",
    "        if not self.drop_last:\n",
    "            n_batches += int(len(self.dataset) % self.batch_size != 0)\n",
    "        return n_batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.__call__()\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoaderNP(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    seed=None,\n",
    ")\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", batch[\"input_ids\"].shape)\n",
    "print(\"Label batch dimensions:\", batch[\"label\"], batch[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caf2a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoaderNP(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "test_loader = DataLoaderNP(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7e28f6",
   "metadata": {},
   "source": [
    "# Initializing a model with pretrained weights\n",
    "- Tensorflow2 does not support Python 3.13 for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22ce2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNorm(768, eps=1e-05, affine=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hf['model'].h[-1].ln_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e34937c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTClassifier(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.pretrained_model = pretrained_model.freeze()\n",
    "        self.classifier = nn.Linear(pretrained_model.h[-1].ln_2.weight.shape[0], \n",
    "                                    num_classes)\n",
    "        self.pretrained_model.h[-1].unfreeze()\n",
    "        self.pretrained_model.ln_f.unfreeze()\n",
    "\n",
    "    def __call__(self, inputs, mask=None, cache=None):\n",
    "        out = self.pretrained_model(inputs, mask, cache)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a06495a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_clf = GPTClassifier(model_hf['model'], num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c547b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model parameters: 124441346\n",
      "trainable parameters: 7090946\n",
      "trainable parameters (pretrained): 7089408\n",
      "trainable parameters (classifier): 1538\n"
     ]
    }
   ],
   "source": [
    "from mlx.utils import tree_flatten\n",
    "print(f\"Pretrained model parameters: {sum(v.size for _, v in tree_flatten(mod_clf.parameters()))}\")\n",
    "print(f\"trainable parameters: {sum(v.size for _, v in tree_flatten(mod_clf.trainable_parameters()))}\")\n",
    "print(f\"trainable parameters (pretrained): {sum(v.size for _, v in tree_flatten(mod_clf.pretrained_model.trainable_parameters()))}\")\n",
    "print(f\"trainable parameters (classifier): {sum(v.size for _, v in tree_flatten(mod_clf.classifier.trainable_parameters()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76d5f697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: array([[5211, 345, 423, 640]], dtype=int32)\n",
      "Inputs dimensions: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer_hf.encode(\"Do you have time\")\n",
    "inputs = mx.expand_dims(mx.array(inputs), axis=0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1736762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs: array([[[0.6055, -1.42779],\n",
      "        [1.60927, -6.17181],\n",
      "        [1.32532, -3.85031],\n",
      "        [2.37668, -3.35481]]], dtype=float32)\n",
      "Outputs dimensions: (1, 4, 2)\n",
      "Last output token: array([[2.37668, -3.35481]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "outputs = mod_clf(mx.stop_gradient(inputs))\n",
    "print(\"Outputs:\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape)\n",
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5fbd7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 0 0\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "probas = nn.softmax(logits, axis=-1)\n",
    "label_logit = mx.argmax(logits)\n",
    "label_sfmx = mx.argmax(probas)\n",
    "\n",
    "print(\"Class label:\", label_logit.item(), label_sfmx.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90b1e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, no_grad, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = mx.array(batch['input_ids']), mx.array(batch['label'])\n",
    "            if no_grad:\n",
    "                input_batch = mx.stop_gradient(input_batch)\n",
    "\n",
    "            # logits of the last output token\n",
    "            logits = model(mx.stop_gradient(input_batch))[:, -1, :]\n",
    "            predicted_labels = mx.argmax(logits, axis=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e525d960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 50.00%\n",
      "Validation accuracy: 50.00%\n",
      "Test accuracy: 45.00%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, mod_clf, True, num_batches=5)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, mod_clf, True, num_batches=5)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, mod_clf, True, num_batches=5)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6de8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ce_loss(model, inputs, targets):\n",
    "    # !!!including model is crucial for gradient calculation; otherwise, gradients are zero\n",
    "    # pad_id = 50256\n",
    "    # logits_all = model(inputs)\n",
    "    # length_idx = (inputs != pad_id).sum(axis=1) - 1\n",
    "    # batch_idx = mx.arange(len(length_idx))\n",
    "    # logits = logits_all[batch_idx, length_idx, :]\n",
    "    logits = model(inputs)[:, -1, :]\n",
    "    return nn.losses.cross_entropy(logits, targets, reduction='mean')\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, no_grad):\n",
    "    input_batch, target_batch = mx.array(input_batch), mx.array(target_batch)\n",
    "    if no_grad:\n",
    "        input_batch = mx.stop_gradient(input_batch)\n",
    "    batch_step_fn = nn.value_and_grad(model, compute_ce_loss)\n",
    "    # logits = model(input_batch)[:, -1, :]\n",
    "    # loss, grad = batch_step_fn(logits, target_batch)\n",
    "    loss, grad = batch_step_fn(model, input_batch, target_batch)\n",
    "    # print(f\"@@@@@ loss {loss.item():.3f}, grad {grad['classifier']['weight'].max():.6f}\")\n",
    "    return loss, grad\n",
    "\n",
    "def calc_loss_loader(data_loader, model, no_grad, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, batch in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss, _ = calc_loss_batch(batch['input_ids'], batch['label'], model, no_grad)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35a38cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.3436\n",
      "Validation loss: 2.9189\n",
      "Test loss: 3.2112\n"
     ]
    }
   ],
   "source": [
    "train_loss = calc_loss_loader(train_loader, mod_clf, True, num_batches=5)\n",
    "val_loss = calc_loss_loader(val_loader, mod_clf, True, num_batches=5)\n",
    "test_loss = calc_loss_loader(test_loader, mod_clf, True, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.4f}\")\n",
    "print(f\"Validation loss: {val_loss:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1532b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, \n",
    "                       eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # mx.eval(model.parameters())\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            input_batch, target_batch = batch['input_ids'], batch['label']\n",
    "            loss, grads = calc_loss_batch(input_batch, target_batch, model, no_grad=False)\n",
    "            # print(f\"Epoch {epoch+1}, step {global_step+1:06d}: loss {loss.item():.3f}, grad {grads['classifier']['weight'].max():.6f}\")\n",
    "            optimizer.update(model, grads)\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(model.parameters(), optimizer.state, loss)\n",
    "            examples_seen += input_batch.size\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Epoch {epoch+1}, step {global_step:06d}: \"\n",
    "                      f\"train loss {train_loss:.3f}, val loss {val_loss:.3f}\")\n",
    "        # calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, True, eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, True, eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    train_loss = calc_loss_loader(train_loader, model, True, eval_iter)\n",
    "    val_loss = calc_loss_loader(val_loader, model, True, eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62a3714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_hf.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97b43d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 000000: train loss 2.375, val loss 3.165\n",
      "Epoch 1, step 000050: train loss 0.455, val loss 0.474\n",
      "Epoch 1, step 000100: train loss 0.071, val loss 0.060\n",
      "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
      "Epoch 2, step 000150: train loss 0.019, val loss 0.115\n",
      "Epoch 2, step 000200: train loss 0.020, val loss 0.037\n",
      "Epoch 2, step 000250: train loss 0.037, val loss 0.083\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Epoch 3, step 000300: train loss 0.044, val loss 0.102\n",
      "Epoch 3, step 000350: train loss 0.107, val loss 0.130\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Epoch 4, step 000400: train loss 0.073, val loss 0.136\n",
      "Epoch 4, step 000450: train loss 0.007, val loss 0.125\n",
      "Epoch 4, step 000500: train loss 0.133, val loss 0.111\n",
      "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
      "Epoch 5, step 000550: train loss 0.006, val loss 0.096\n",
      "Epoch 5, step 000600: train loss 0.267, val loss 0.062\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 1.71 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "mx.random.seed(123)\n",
    "mod_clf = GPTClassifier(model_hf['model'], num_classes=2)\n",
    "optimizer = optim.AdamW(learning_rate=5e-5, weight_decay=1e-1)\n",
    "\n",
    "# TODO: training loss is not decreasing. needs investigation. \n",
    "# TODO: fix datastream first.\n",
    "# e.g., https://apeatling.com/articles/simple-guide-to-local-llm-fine-tuning-on-a-mac-with-mlx/ ??\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_model_simple(\n",
    "    mod_clf, train_loader, val_loader, optimizer, None, \n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25d20064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.95, 0.975, 0.975, 0.95, 1.0], [0.95, 0.95, 0.975, 0.95, 0.975])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accs, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8327d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.13%\n",
      "Validation accuracy: 97.92%\n",
      "Test accuracy: 96.28%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, mod_clf, True)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, mod_clf, True)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, mod_clf, True)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-from-scratch-mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
