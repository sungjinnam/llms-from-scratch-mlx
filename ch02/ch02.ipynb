{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c6c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.data as dx\n",
    "import mlx.nn as nn\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb2843",
   "metadata": {},
   "source": [
    "# Dataloader with a tokenizer and a sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a713dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_dataset_v1(txt, tokenizer, max_length, stride, batch_size, shuffle=True):\n",
    "    # input_ids = []\n",
    "    # target_ids = []\n",
    "    token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "    assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
    "\n",
    "    # sliding window to chunk the input text with overlaps\n",
    "    chunks = []\n",
    "    for i in range(0, len(token_ids) - max_length, stride):\n",
    "        input_chunk = token_ids[i: i+max_length]\n",
    "        target_chunk = token_ids[i+1: i+max_length+1]\n",
    "        chunks.append({\n",
    "            \"input_ids\": mx.array(input_chunk),\n",
    "            \"target_ids\": mx.array(target_chunk)\n",
    "        })\n",
    "        # input_ids.append(mx.array(input_chunk))\n",
    "        # target_ids.append(mx.array(target_chunk))\n",
    "\n",
    "    # mlx-data pipeline\n",
    "    stream = dx.buffer_from_vector(chunks)\n",
    "    stream = stream.to_stream()\n",
    "    if shuffle:\n",
    "        stream = stream.shuffle(buffer_size=len(chunks))\n",
    "    stream = stream.batch(batch_size)\n",
    "    # TODO: batched numpy arrays to mlx arrays\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b9ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "dataloader = gpt_dataset_v1(\"this is a test sentence with mlx\", tokenizer, 4, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7940bfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target_ids': array([[ 318,  257, 1332, 6827]], dtype=int32),\n",
       "  'input_ids': array([[5661,  318,  257, 1332]], dtype=int32)},\n",
       " {'target_ids': array([[ 1332,  6827,   351, 25962]], dtype=int32),\n",
       "  'input_ids': array([[ 257, 1332, 6827,  351]], dtype=int32)}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20b8c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test sentence'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([5661, 318, 257, 1332, 6827])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da3cf7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./the-verdict.txt\", \"r\") as f:\n",
    "    txt = f.read()\n",
    "dataset = gpt_dataset_v1(txt, tokenizer, 256, 128, \n",
    "                         batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1069993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_ids': array([[ 1807,   673,   750, ...,  2900,   656,   257],\n",
      "       [  550,  1775,   683, ...,   271, 10899,    11],\n",
      "       [ 1544, 13818,  4622, ...,   286,   616, 12036],\n",
      "       ...,\n",
      "       [  616,  4286,   705, ...,   910,   416,  4150],\n",
      "       [  508,   550, 18459, ...,   198,   198,  3347],\n",
      "       [ 1165,   881, 40642, ...,   366,  2215,   673]],\n",
      "      shape=(8, 256), dtype=int32), 'input_ids': array([[  273,  1807,   673, ..., 15185,  2900,   656],\n",
      "       [  314,   550,  1775, ...,   402,   271, 10899],\n",
      "       [  198,  1544, 13818, ..., 13476,   286,   616],\n",
      "       ...,\n",
      "       [  286,   616,  4286, ...,   470,   910,   416],\n",
      "       [   11,   508,   550, ...,   526,   198,   198],\n",
      "       [ 1310,  1165,   881, ...,    13,   366,  2215]],\n",
      "      shape=(8, 256), dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(dataset)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2523b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_ids': array([[  198,   198,     1, ...,   262,  5385, 41186],\n",
      "       [ 1234,  8737,   656, ...,   336,  8375,   503],\n",
      "       [10899,   550,   366, ...,  2745,    11,   314],\n",
      "       ...,\n",
      "       [  683,     0,  3226, ...,   616,   835,   286],\n",
      "       [17728,   257,  8500, ...,   465,  2330, 22645],\n",
      "       [ 1908,   329,   345, ...,  2474,   198,   198]],\n",
      "      shape=(8, 256), dtype=int32), 'input_ids': array([[   13,   198,   198, ...,   286,   262,  5385],\n",
      "       [  284,  1234,  8737, ...,   290,   336,  8375],\n",
      "       [  271, 10899,   550, ..., 29543,  2745,    11],\n",
      "       ...,\n",
      "       [12036,   683,     0, ...,   284,   616,   835],\n",
      "       [   11, 17728,   257, ...,   422,   465,  2330],\n",
      "       [  673,  1908,   329, ...,   514,  2474,   198]],\n",
      "      shape=(8, 256), dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074bcd71",
   "metadata": {},
   "source": [
    "# Create token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7852f43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.774268, 0.240581, -0.233984],\n",
       "        [0.496537, 0.00315234, -0.397442],\n",
       "        [-1.25292, -0.244347, 0.326495],\n",
       "        [-0.292979, 0.258776, -0.41039],\n",
       "        [-0.225358, -0.997256, -0.623246],\n",
       "        [-0.424824, 0.875692, 0.277775]], dtype=float32),\n",
       " array([[-0.292979, 0.258776, -0.41039]], dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "mx.random.seed(123)\n",
    "embedding_layer = nn.Embedding(vocab_size, output_dim)\n",
    "embedding_layer.weight, embedding_layer(mx.array([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238de5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.25292, -0.244347, 0.326495],\n",
       "       [-0.292979, 0.258776, -0.41039],\n",
       "       [-0.424824, 0.875692, 0.277775],\n",
       "       [0.496537, 0.00315234, -0.397442]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = mx.array([2,3,5,1])\n",
    "embedding_layer(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84cf0d",
   "metadata": {},
   "source": [
    "# Encoding word positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8dab0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5b77592",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataset = gpt_dataset_v1(txt, tokenizer, max_length, max_length, \n",
    "                         batch_size=8, shuffle=False)\n",
    "data_iter = iter(dataset)\n",
    "first_batch = next(data_iter)\n",
    "inputs = first_batch[\"input_ids\"]\n",
    "targets = first_batch[\"target_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "945019b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   40,   367,  2885,  1464],\n",
       "        [ 1807,  3619,   402,   271],\n",
       "        [10899,  2138,   257,  7026],\n",
       "        [15632,   438,  2016,   257],\n",
       "        [  922,  5891,  1576,   438],\n",
       "        [  568,   340,   373,   645],\n",
       "        [ 1049,  5975,   284,   502],\n",
       "        [  284,  3285,   326,    11]], dtype=int32),\n",
       " (8, 4),\n",
       " array([[  367,  2885,  1464,  1807],\n",
       "        [ 3619,   402,   271, 10899],\n",
       "        [ 2138,   257,  7026, 15632],\n",
       "        [  438,  2016,   257,   922],\n",
       "        [ 5891,  1576,   438,   568],\n",
       "        [  340,   373,   645,  1049],\n",
       "        [ 5975,   284,   502,   284],\n",
       "        [ 3285,   326,    11,   287]], dtype=int32),\n",
       " (8, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, inputs.shape, targets, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08e0d574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00192652, 0.0283879, 0.0952962, ..., 0.0396189, 0.00657118, -0.0729339],\n",
       "        [0.0438855, -0.00700499, 0.0120941, ..., -0.093685, 0.00781714, 0.0639005],\n",
       "        [-0.0585878, 0.0482262, -0.0910247, ..., 0.0116109, 0.000168937, -0.128424],\n",
       "        [0.0250007, -0.0731869, -0.0576285, ..., 0.0203022, 0.0630568, 0.00691061]], dtype=float32),\n",
       " (8, 4, 256))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(mx.array(inputs))\n",
    "token_embeddings[0], token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "898b93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edc3527f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.0957718, -0.0953044, 0.0774341, ..., -0.118451, -0.0242793, 0.00254553], dtype=float32),\n",
       " (4, 256))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(mx.arange(max_length))\n",
    "pos_embeddings[0], pos_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fae62b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.0976984, -0.0669165, 0.17273, ..., -0.078832, -0.0177081, -0.0703884],\n",
       "        [0.132454, -0.00132004, 0.0429362, ..., -0.0658143, -0.118927, 0.0793585],\n",
       "        [0.0234318, 0.198176, -0.0387605, ..., 0.0469349, -0.0657431, -0.277958],\n",
       "        [0.0258491, -0.0750647, -0.0575229, ..., 0.0165579, 0.152153, 0.0663575]], dtype=float32),\n",
       " (8, 4, 256))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "input_embeddings[0], input_embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-from-scratch-mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
